# Report:

This Spring 2023, I learned many new things about containers and orchestration through Docker and Kubernetes. I was first introduced through reading about the theoretical and conceptual aspects of containerization and its uses and applications. Furthermore, the benefits of containers are expanded with orchestration which can automate multiple container workloads. Through it all, efficient usage of resources and cost-effectiveness may be achieved through containerization and orchestration. Docker and Kubernetes are the most popular containerization and orchestration tools which is why it made sense for me to use them in my independent study.

I first started by learning how to use Docker to run a default Nginx image. I was able to accomplish this on Windows using the Docker desktop application, and also on a Cloudlab machine running Ubuntu. Next, my larger challenge was figuring out how to translate this to running an Nginx image on a single-node Kubernetes cluster. Admittedly, this took up the majority of my time as I started to run into a busier school semester while trying to figure out my way past multiple errors during setup. I initially spent a lot of time researching the best way to install Kubernetes, as well as learning about how it works to make sense of the commands that install it.
My first error occurred when trying to initialize the control plane for Kubernetes. I would get an error regarding the container runtime:
```
[ERROR CRI]: container runtime is not running: output: time="2023-04-10T15:52:45-06:00" level=fatal msg="validate service connection: CRI v1 runtime API is not implemented for endpoint \"unix:///var/run/containerd/containerd.sock\": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService"
, error: exit status 1
```
I was really confused about where the root of the problem was because I thought I had the correct container runtime through installing Docker Engine. I checked out a couple of posts online regarding this error message, but other people seemed to get this error message due to a different reason. However, there were a couple of posts that mentioned cgroup drivers. When I reopened the official Kubernetes article to re-install everything after my experiment expired one day, I noticed a text label that mentioned how cgroup drivers had to be configured manually for Linux users who ran Kubernetes 1.24+. cri-dockerd is also open source, and I was able to successfully follow the directions from the developer’s site to successfully download it with a couple of modifications to certain commands that did not work. Because of this, I also had Go installed to build cri-dockerd. After finishing this step, I was able to successfully initialize the cluster control plane. With the initialization of the control plane, I would also copy the join command and id that worker nodes would need to be connected to the master node.

Finally, I went on to deploy a single-node nginx cluster on Kubernetes. Using the Kubernetes documentation, I went straight to trying to deploy a cluster. This did not work, however, as I did not know that I needed to configure a network manager regardless of whether or not the cluster was a single-node cluster. Furthermore, the documentation tutorial ended with the instructions for initializing the control plane, and I did not see anything about configuring a network before reaching the deployment stage, so I was left a bit confused. At this point, I started to look at multi-node cluster tutorials and saw how the network configuration was a necessary step to activating a pod so I could create my deployment. I consulted multiple resources to find a working template for the network configuration and ended up using Calico as it is a popular choice for simple setups like this. I read through the .yaml files and documentation and saw the main attribute that would take in my pod’s cidr value. I used the create -f command to create a resource using Calico’s yaml file, but after mistakenly entering the wrong cidr value I learned to use delete -f which can also delete a resource file by filename, just like create -f. This is because create -f does not allow you to modify the resource after creation. 

At this point, I was supposed to be able to create my deployment, but I was still unable to do so because my pod status was still displayed as NotReady even though the networking configuration had been successfully set up. By sheer chance, I decided to create an image to store my progress so far, and in doing so, Cloudlab would have to reboot my machine. After rebooting, I had to repeat some commands that were reset, like swapoff, but when I checked back on the pod, it was finally ready. It is possible that when I applied a resource file for the second time, I had to restart the pod to apply the change. 

After this, I could create a deployment with a default Nginx image. I also created a service so I could access the deployment from my browser with the port value assigned to the NodePort service. After creating the service, I found the port the service opened and used that to access the Nginx deployment from my browser. With this, I could finally observe that my deployment was working.

During this entire learning process, I consulted several resources and videos including the official Kubernetes documentation and several tutorials that explained how Docker and Kubernetes worked alongside their implementation. The theory behind Kubernetes was also important to help me understand the paper Load Balancers Need In-Band Feedback Control paper that the graduate student I would be helping was working on. The paper advocates for methods that can be used to measure server response times which can in turn improve load balancer performance. As load balancers are incredibly relevant and useful in the present technology, finding ways to enhance their performance without sacrificing other qualities or demanding widespread change would be an important step to optimizing application performance. The paper also received a positive response from the community, encouraging further research to take place.

This project would not have happened without the help of my professor, Srinivas Narayana who introduced me to several relevant topics and resources and guided me through my learning. I also have a graduate student staff member, Bhavana Shobana to thank for helping me to understand more about Kubernetes and to debug my errors. She introduced several new commands that I could use to check node descriptions and statuses which could output valuable information regarding why a node may be malfunctioning.
